{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dd0c49cb",
      "metadata": {
        "id": "dd0c49cb"
      },
      "source": [
        "# [Hands-On] N-gram 생성 및 BOW 벡터화 기초\n",
        "\n",
        "- Author: Sangkeun Jung (hugmanskj@gmail.com)\n",
        "\n",
        "> 교육 목적\n",
        "\n",
        "**Copyright**: All rights reserved\n",
        "\n",
        "---\n",
        "\n",
        "## 개요\n",
        "\n",
        "N-gram의 개념을 이해하고, BOW(Bag-of-Words) 벡터화 기법을 실습합니다.\n",
        "\n",
        "\n",
        "**학습 목표**:\n",
        "1. Unigram, Bigram, Trigram 생성 방법 이해\n",
        "2. N-gram을 이용한 BOW 벡터 생성\n",
        "3. 문장을 고정 차원의 벡터로 표현하는 방법 습득\n",
        "4. N-gram이 문맥 정보를 어떻게 보존하는지 이해"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c8c076f",
      "metadata": {
        "id": "9c8c076f"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd28f19",
      "metadata": {
        "id": "8fd28f19"
      },
      "source": [
        "## 1. 라이브러리 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f292c72",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f292c72",
        "outputId": "20631cca-567b-46c7-a430-6c3bc1e2b48d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "라이브러리 로드 완료!\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "\n",
        "print(\"라이브러리 로드 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0b3479f",
      "metadata": {
        "id": "d0b3479f"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95d7c73e",
      "metadata": {
        "id": "95d7c73e"
      },
      "source": [
        "## 2. N-gram 생성 함수 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0f8c82",
      "metadata": {
        "id": "db0f8c82"
      },
      "source": [
        "### 2.1 N-gram 생성 함수\n",
        "\n",
        "토큰 리스트로부터 n-gram을 생성하는 함수를 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21582ef",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "c21582ef"
      },
      "outputs": [],
      "source": [
        "def generate_ngrams(tokens, n):\n",
        "    \"\"\"\n",
        "    토큰 리스트로부터 n-gram을 생성합니다.\n",
        "\n",
        "    Args:\n",
        "        tokens: 토큰 리스트 (예: ['나는', '밥을', '먹었다'])\n",
        "        n: n-gram의 크기 (1=unigram, 2=bigram, 3=trigram)\n",
        "\n",
        "    Returns:\n",
        "        n-gram 리스트 (예: n=2일 때 ['나는 밥을', '밥을 먹었다'])\n",
        "\n",
        "    예시:\n",
        "        tokens = ['나는', '밥을', '먹었다']\n",
        "        generate_ngrams(tokens, 1) → ['나는', '밥을', '먹었다']\n",
        "        generate_ngrams(tokens, 2) → ['나는 밥을', '밥을 먹었다']\n",
        "        generate_ngrams(tokens, 3) → ['나는 밥을 먹었다']\n",
        "    \"\"\"\n",
        "    ngrams = []\n",
        "\n",
        "\n",
        "    for i in range(len(tokens) - n + 1):\n",
        "        ngram = ' '.join(tokens[i:i+n])\n",
        "        ngrams.append(ngram)\n",
        "\n",
        "    return ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e45540e6",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45540e6",
        "outputId": "76d8ae75-e292-4777-a618-92eda05662dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "N-gram 생성 테스트\n",
            "======================================================================\n",
            "\n",
            "입력 토큰: ['나는', '밥을', '먹었다']\n",
            "\n",
            "Unigram (n=1): ['나는', '밥을', '먹었다']\n",
            "Bigram (n=2): ['나는 밥을', '밥을 먹었다']\n",
            "Trigram (n=3): ['나는 밥을 먹었다']\n"
          ]
        }
      ],
      "source": [
        "# 함수 테스트\n",
        "test_tokens = ['나는', '밥을', '먹었다']\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"N-gram 생성 테스트\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\n입력 토큰:\", test_tokens)\n",
        "print(\"\\nUnigram (n=1):\", generate_ngrams(test_tokens, 1))\n",
        "print(\"Bigram (n=2):\", generate_ngrams(test_tokens, 2))\n",
        "print(\"Trigram (n=3):\", generate_ngrams(test_tokens, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a38de2d1",
      "metadata": {
        "id": "a38de2d1"
      },
      "source": [
        "### 2.2 Vocabulary 생성 함수\n",
        "\n",
        "여러 문장으로부터 전체 vocabulary를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d114585b",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "d114585b"
      },
      "outputs": [],
      "source": [
        "def create_vocabulary(sentences, ngram_range=(1, 2)):\n",
        "    \"\"\"\n",
        "    여러 문장으로부터 vocabulary를 생성합니다.\n",
        "\n",
        "    Args:\n",
        "        sentences: 토큰화된 문장들의 리스트\n",
        "        ngram_range: n-gram 범위 (min_n, max_n)\n",
        "                     예: (1, 2)는 unigram과 bigram 모두 포함\n",
        "\n",
        "    Returns:\n",
        "        정렬된 vocabulary 리스트\n",
        "\n",
        "    예시:\n",
        "        sentences = [['강한', '비가', '내렸다'], ['비가', '많이', '내렸다']]\n",
        "        create_vocabulary(sentences, (1, 2))\n",
        "        → ['강한', '내렸다', '많이', '비가', '강한 비가', '비가 내렸다', '비가 많이']\n",
        "    \"\"\"\n",
        "    all_ngrams = set()\n",
        "\n",
        "    min_n, max_n = ngram_range\n",
        "\n",
        "    for tokens in sentences:\n",
        "        for n in range(min_n, max_n + 1):\n",
        "            ngrams = generate_ngrams(tokens, n)\n",
        "            all_ngrams.update(ngrams)\n",
        "\n",
        "    # 정렬하여 일관된 순서 유지\n",
        "    vocabulary = sorted(all_ngrams)\n",
        "    return vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a55f7f",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56a55f7f",
        "outputId": "4860bbbc-d0e5-4c4c-c2d2-4c3b2c3a2d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Vocabulary 생성 테스트\n",
            "======================================================================\n",
            "\n",
            "입력 문장:\n",
            "  1. 강한 비가 내렸다\n",
            "  2. 비가 많이 내렸다\n",
            "\n",
            "생성된 Vocabulary (8개):\n",
            "   1. 강한\n",
            "   2. 강한 비가\n",
            "   3. 내렸다\n",
            "   4. 많이\n",
            "   5. 많이 내렸다\n",
            "   6. 비가\n",
            "   7. 비가 내렸다\n",
            "   8. 비가 많이\n"
          ]
        }
      ],
      "source": [
        "# 함수 테스트\n",
        "test_sentences = [\n",
        "    ['강한', '비가', '내렸다'],\n",
        "    ['비가', '많이', '내렸다']\n",
        "]\n",
        "\n",
        "vocab = create_vocabulary(test_sentences, ngram_range=(1, 2))\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Vocabulary 생성 테스트\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\n입력 문장:\")\n",
        "for i, sent in enumerate(test_sentences, 1):\n",
        "    print(\"  %d. %s\" % (i, ' '.join(sent)))\n",
        "\n",
        "print(\"\\n생성된 Vocabulary (%d개):\" % len(vocab))\n",
        "for i, feature in enumerate(vocab, 1):\n",
        "    print(\"  %2d. %s\" % (i, feature))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81a62923",
      "metadata": {
        "id": "81a62923"
      },
      "source": [
        "### 2.3 BOW 벡터 변환 함수\n",
        "\n",
        "토큰 리스트를 BOW 벡터로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "987902b8",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "987902b8"
      },
      "outputs": [],
      "source": [
        "def text_to_bow_vector(tokens, vocabulary, ngram_range=(1, 2)):\n",
        "    \"\"\"\n",
        "    토큰 리스트를 BOW 벡터로 변환합니다.\n",
        "\n",
        "    Args:\n",
        "        tokens: 토큰 리스트\n",
        "        vocabulary: 전체 어휘 리스트\n",
        "        ngram_range: n-gram 범위\n",
        "\n",
        "    Returns:\n",
        "        BOW 벡터 (vocabulary 크기와 동일한 차원)\n",
        "\n",
        "    예시:\n",
        "        tokens = ['강한', '비가', '내렸다']\n",
        "        vocabulary = ['강한', '비가', '내렸다', '많이', '강한 비가', '비가 내렸다']\n",
        "        vector = text_to_bow_vector(tokens, vocabulary, (1, 2))\n",
        "        → [1, 1, 1, 0, 1, 1]  (각 feature의 출현 횟수)\n",
        "    \"\"\"\n",
        "    # vocabulary를 인덱스로 매핑\n",
        "    vocab_to_idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
        "\n",
        "    # 0으로 초기화된 벡터 생성\n",
        "    vector = np.zeros(len(vocabulary), dtype=int)\n",
        "\n",
        "    min_n, max_n = ngram_range\n",
        "\n",
        "    for n in range(min_n, max_n + 1):\n",
        "        ngrams = generate_ngrams(tokens, n)\n",
        "        for ngram in ngrams:\n",
        "            if ngram in vocab_to_idx:\n",
        "                idx = vocab_to_idx[ngram]\n",
        "                vector[idx] += 1\n",
        "\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7754869e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7754869e",
        "outputId": "ecdc754f-d1f9-44ff-c6e2-578ba7cd6828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "BOW 벡터 변환 테스트\n",
            "======================================================================\n",
            "\n",
            "입력 토큰: ['강한', '비가', '내렸다']\n",
            "\n",
            "Vocabulary:\n",
            "  0. 강한\n",
            "  1. 비가\n",
            "  2. 내렸다\n",
            "  3. 많이\n",
            "  4. 강한 비가\n",
            "  5. 비가 내렸다\n",
            "  6. 비가 많이\n",
            "\n",
            "생성된 벡터: [np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0)]\n",
            "\n",
            "Feature 출현 횟수:\n",
            "  강한: 1회\n",
            "  비가: 1회\n",
            "  내렸다: 1회\n",
            "  강한 비가: 1회\n",
            "  비가 내렸다: 1회\n"
          ]
        }
      ],
      "source": [
        "# 함수 테스트\n",
        "test_tokens = ['강한', '비가', '내렸다']\n",
        "test_vocab = ['강한', '비가', '내렸다', '많이', '강한 비가', '비가 내렸다', '비가 많이']\n",
        "\n",
        "vector = text_to_bow_vector(test_tokens, test_vocab, ngram_range=(1, 2))\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"BOW 벡터 변환 테스트\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\n입력 토큰:\", test_tokens)\n",
        "print(\"\\nVocabulary:\")\n",
        "for i, feat in enumerate(test_vocab):\n",
        "    print(\"  %d. %s\" % (i, feat))\n",
        "\n",
        "print(\"\\n생성된 벡터:\", list(vector))\n",
        "print(\"\\nFeature 출현 횟수:\")\n",
        "for i, count in enumerate(vector):\n",
        "    if count > 0:\n",
        "        print(\"  %s: %d회\" % (test_vocab[i], count))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aab11193",
      "metadata": {
        "id": "aab11193"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17ea3870",
      "metadata": {
        "id": "17ea3870"
      },
      "source": [
        "## 3. 실습 예제 1: 슬라이드 예제 재현 (Unigram + Bigram)\n",
        "\n",
        "**문장들**:\n",
        "- 문장 1: \"강한 비가 내렸다\"\n",
        "- 문장 2: \"비가 많이 내렸다\"\n",
        "- 문장 3: \"어제 강한 바람과 비가 내렸다\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd132ccd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd132ccd",
        "outputId": "0502129e-93c8-4ef2-aaba-1deeb47220c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "실습 예제 1: 슬라이드 예제 재현 (Unigram + Bigram)\n",
            "======================================================================\n",
            "\n",
            "[입력 문장들]\n",
            "문장 1: 강한 비가 내렸다\n",
            "문장 2: 비가 많이 내렸다\n",
            "문장 3: 어제 강한 바람과 비가 내렸다\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"실습 예제 1: 슬라이드 예제 재현 (Unigram + Bigram)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 토큰화된 문장들 (띄어쓰기 기준)\n",
        "sentences = [\n",
        "    ['강한', '비가', '내렸다'],\n",
        "    ['비가', '많이', '내렸다'],\n",
        "    ['어제', '강한', '바람과', '비가', '내렸다']\n",
        "]\n",
        "\n",
        "print(\"\\n[입력 문장들]\")\n",
        "for i, sent in enumerate(sentences, 1):\n",
        "    print(\"문장 %d: %s\" % (i, ' '.join(sent)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27c0a37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c27c0a37",
        "outputId": "9e5d927c-b63e-4975-c6ee-0bb96ee616be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Step 1] Unigram 생성\n",
            "문장 1: ['강한', '비가', '내렸다']\n",
            "문장 2: ['비가', '많이', '내렸다']\n",
            "문장 3: ['어제', '강한', '바람과', '비가', '내렸다']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Unigram 생성\n",
        "print(\"\\n[Step 1] Unigram 생성\")\n",
        "for i, tokens in enumerate(sentences, 1):\n",
        "    unigrams = generate_ngrams(tokens, n=1)\n",
        "    print(\"문장 %d: %s\" % (i, str(unigrams)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd0a96d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd0a96d8",
        "outputId": "331c9ede-a727-42d9-8327-9b5b8ad8796b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Step 2] Bigram 생성\n",
            "문장 1: ['강한 비가', '비가 내렸다']\n",
            "문장 2: ['비가 많이', '많이 내렸다']\n",
            "문장 3: ['어제 강한', '강한 바람과', '바람과 비가', '비가 내렸다']\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Bigram 생성\n",
        "print(\"\\n[Step 2] Bigram 생성\")\n",
        "for i, tokens in enumerate(sentences, 1):\n",
        "    bigrams = generate_ngrams(tokens, n=2)\n",
        "    print(\"문장 %d: %s\" % (i, str(bigrams)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd51c0c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd51c0c4",
        "outputId": "9a1a200f-2e37-4082-e5ee-10acea4c4f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Step 3] 전체 Vocabulary 생성 (Unigram + Bigram)\n",
            "총 13개의 feature\n",
            "\n",
            "Vocabulary:\n",
            "   0. 강한\n",
            "   1. 강한 바람과\n",
            "   2. 강한 비가\n",
            "   3. 내렸다\n",
            "   4. 많이\n",
            "   5. 많이 내렸다\n",
            "   6. 바람과\n",
            "   7. 바람과 비가\n",
            "   8. 비가\n",
            "   9. 비가 내렸다\n",
            "  10. 비가 많이\n",
            "  11. 어제\n",
            "  12. 어제 강한\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Vocabulary 생성 (Unigram + Bigram)\n",
        "print(\"\\n[Step 3] 전체 Vocabulary 생성 (Unigram + Bigram)\")\n",
        "vocabulary = create_vocabulary(sentences, ngram_range=(1, 2))\n",
        "print(\"총 %d개의 feature\" % len(vocabulary))\n",
        "print(\"\\nVocabulary:\")\n",
        "for idx, feature in enumerate(vocabulary):\n",
        "    print(\"  %2d. %s\" % (idx, feature))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "785961a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "785961a7",
        "outputId": "bff82ebd-71ba-4818-feb3-2e3f7affb1c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Step 4] 각 문장을 13차원 벡터로 표현\n",
            "\n",
            "(슬라이드 14페이지 참조)\n",
            "\n",
            "문장 1 벡터: [np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0)]\n",
            "  원문: 강한 비가 내렸다\n",
            "  포함된 features:\n",
            "    - 강한: 1회\n",
            "    - 강한 비가: 1회\n",
            "    - 내렸다: 1회\n",
            "    - 비가: 1회\n",
            "    - 비가 내렸다: 1회\n",
            "\n",
            "문장 2 벡터: [np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0)]\n",
            "  원문: 비가 많이 내렸다\n",
            "  포함된 features:\n",
            "    - 내렸다: 1회\n",
            "    - 많이: 1회\n",
            "    - 많이 내렸다: 1회\n",
            "    - 비가: 1회\n",
            "    - 비가 많이: 1회\n",
            "\n",
            "문장 3 벡터: [np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1)]\n",
            "  원문: 어제 강한 바람과 비가 내렸다\n",
            "  포함된 features:\n",
            "    - 강한: 1회\n",
            "    - 강한 바람과: 1회\n",
            "    - 내렸다: 1회\n",
            "    - 바람과: 1회\n",
            "    - 바람과 비가: 1회\n",
            "    - 비가: 1회\n",
            "    - 비가 내렸다: 1회\n",
            "    - 어제: 1회\n",
            "    - 어제 강한: 1회\n"
          ]
        }
      ],
      "source": [
        "# Step 4: 각 문장을 벡터로 변환\n",
        "print(\"\\n[Step 4] 각 문장을 13차원 벡터로 표현\")\n",
        "print(\"\\n(슬라이드 14페이지 참조)\")\n",
        "\n",
        "for i, tokens in enumerate(sentences, 1):\n",
        "    vector = text_to_bow_vector(tokens, vocabulary, ngram_range=(1, 2))\n",
        "    print(\"\\n문장 %d 벡터: %s\" % (i, list(vector)))\n",
        "    print(\"  원문: %s\" % ' '.join(tokens))\n",
        "\n",
        "    # 어떤 feature가 포함되었는지 출력\n",
        "    print(\"  포함된 features:\")\n",
        "    for idx, count in enumerate(vector):\n",
        "        if count > 0:\n",
        "            print(\"    - %s: %d회\" % (vocabulary[idx], count))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb3d4d3d",
      "metadata": {
        "id": "bb3d4d3d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "655ef85a",
      "metadata": {
        "id": "655ef85a"
      },
      "source": [
        "## 4. 실습 예제 2: 영어 문장으로 연습\n",
        "\n",
        "영어 예제로 추가 연습을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6caf898",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6caf898",
        "outputId": "a4be6abe-0e5e-47fe-d22d-73c64101bb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "실습 예제 2: 영어 문장으로 연습\n",
            "======================================================================\n",
            "\n",
            "[입력 문장들]\n",
            "문장 1: i love machine learning\n",
            "문장 2: machine learning is fun\n",
            "문장 3: i study machine learning\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"실습 예제 2: 영어 문장으로 연습\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "sentences_en = [\n",
        "    ['i', 'love', 'machine', 'learning'],\n",
        "    ['machine', 'learning', 'is', 'fun'],\n",
        "    ['i', 'study', 'machine', 'learning']\n",
        "]\n",
        "\n",
        "print(\"\\n[입력 문장들]\")\n",
        "for i, sent in enumerate(sentences_en, 1):\n",
        "    print(\"문장 %d: %s\" % (i, ' '.join(sent)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "493f385d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "493f385d",
        "outputId": "9e2eb879-45d9-41b6-9028-8153c798d798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Unigram만 사용한 경우 ---\n",
            "Vocabulary (크기 7): ['fun', 'i', 'is', 'learning', 'love', 'machine', 'study']\n",
            "문장 1 벡터: [np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0)]\n",
            "문장 2 벡터: [np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0)]\n",
            "문장 3 벡터: [np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1)]\n"
          ]
        }
      ],
      "source": [
        "# Unigram만 사용\n",
        "print(\"\\n--- Unigram만 사용한 경우 ---\")\n",
        "vocab_unigram = create_vocabulary(sentences_en, ngram_range=(1, 1))\n",
        "print(\"Vocabulary (크기 %d): %s\" % (len(vocab_unigram), str(vocab_unigram)))\n",
        "\n",
        "for i, tokens in enumerate(sentences_en, 1):\n",
        "    vector = text_to_bow_vector(tokens, vocab_unigram, ngram_range=(1, 1))\n",
        "    print(\"문장 %d 벡터: %s\" % (i, list(vector)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb742d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fb742d0",
        "outputId": "b5c44e2c-1fbf-41a5-eae9-fac3164e1658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Unigram + Bigram 사용한 경우 ---\n",
            "Vocabulary (크기 14): ['fun', 'i', 'i love', 'i study', 'is', 'is fun', 'learning', 'learning is', 'love', 'love machine', 'machine', 'machine learning', 'study', 'study machine']\n",
            "문장 1 벡터: [np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0)]\n",
            "문장 2 벡터: [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0)]\n",
            "문장 3 벡터: [np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1)]\n",
            "\n",
            "✓ Bigram을 추가하면 vocabulary 크기가 증가합니다.\n",
            "  Unigram만: 7개\n",
            "  Unigram+Bigram: 14개\n",
            "✓ 하지만 문맥 정보가 더 잘 반영됩니다!\n"
          ]
        }
      ],
      "source": [
        "# Unigram + Bigram 사용\n",
        "print(\"\\n--- Unigram + Bigram 사용한 경우 ---\")\n",
        "vocab_bigram = create_vocabulary(sentences_en, ngram_range=(1, 2))\n",
        "print(\"Vocabulary (크기 %d): %s\" % (len(vocab_bigram), str(vocab_bigram)))\n",
        "\n",
        "for i, tokens in enumerate(sentences_en, 1):\n",
        "    vector = text_to_bow_vector(tokens, vocab_bigram, ngram_range=(1, 2))\n",
        "    print(\"문장 %d 벡터: %s\" % (i, list(vector)))\n",
        "\n",
        "print(\"\\n✓ Bigram을 추가하면 vocabulary 크기가 증가합니다.\")\n",
        "print(\"  Unigram만: %d개\" % len(vocab_unigram))\n",
        "print(\"  Unigram+Bigram: %d개\" % len(vocab_bigram))\n",
        "print(\"✓ 하지만 문맥 정보가 더 잘 반영됩니다!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b03de9d",
      "metadata": {
        "id": "5b03de9d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e05eb04d",
      "metadata": {
        "id": "e05eb04d"
      },
      "source": [
        "## 5. 연습 문제 1: 다양한 N-gram 비교\n",
        "\n",
        "같은 문장들을 Unigram, Bigram, Trigram, Unigram+Bigram으로\n",
        "각각 벡터화하고 결과를 비교해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47274939",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47274939",
        "outputId": "387a6264-1c17-4568-9979-2576044c51a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "연습 문제 1: 다양한 N-gram 설정 비교\n",
            "======================================================================\n",
            "\n",
            "[입력 문장들]\n",
            "문장 1: 자연어 처리는 재미있다\n",
            "문장 2: 기계 학습은 유용하다\n",
            "문장 3: 자연어 처리와 기계 학습\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"연습 문제 1: 다양한 N-gram 설정 비교\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "sentences_kr = [\n",
        "    ['자연어', '처리는', '재미있다'],\n",
        "    ['기계', '학습은', '유용하다'],\n",
        "    ['자연어', '처리와', '기계', '학습']\n",
        "]\n",
        "\n",
        "print(\"\\n[입력 문장들]\")\n",
        "for i, sent in enumerate(sentences_kr, 1):\n",
        "    print(\"문장 %d: %s\" % (i, ' '.join(sent)))\n",
        "\n",
        "# TODO: 다음 설정들로 각각 vocabulary를 만들고 벡터화 결과를 비교하세요\n",
        "# 1. Unigram only: (1, 1)\n",
        "# 2. Bigram only: (2, 2)\n",
        "# 3. Trigram only: (3, 3)\n",
        "# 4. Unigram + Bigram: (1, 2)\n",
        "# 5. Unigram + Bigram + Trigram: (1, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78445179",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78445179",
        "outputId": "f9ed9c12-b6d1-4f3d-8e61-bece25086ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Unigram only ---\n",
            "Vocabulary 크기: 8\n",
            "Features: ['기계', '유용하다', '자연어', '재미있다', '처리는', '처리와', '학습', '학습은']\n",
            "문장 1 벡터 (non-zero만): [('자연어', 1), ('재미있다', 1), ('처리는', 1)]\n",
            "\n",
            "--- Bigram only ---\n",
            "Vocabulary 크기: 7\n",
            "Features: ['기계 학습', '기계 학습은', '자연어 처리는', '자연어 처리와', '처리는 재미있다', '처리와 기계', '학습은 유용하다']\n",
            "문장 1 벡터 (non-zero만): [('자연어 처리는', 1), ('처리는 재미있다', 1)]\n",
            "\n",
            "--- Trigram only ---\n",
            "Vocabulary 크기: 4\n",
            "Features: ['기계 학습은 유용하다', '자연어 처리는 재미있다', '자연어 처리와 기계', '처리와 기계 학습']\n",
            "문장 1 벡터 (non-zero만): [('자연어 처리는 재미있다', 1)]\n",
            "\n",
            "--- Unigram + Bigram ---\n",
            "Vocabulary 크기: 15\n",
            "Features: ['기계', '기계 학습', '기계 학습은', '유용하다', '자연어', '자연어 처리는', '자연어 처리와', '재미있다', '처리는', '처리는 재미있다'] ...\n",
            "문장 1 벡터 (non-zero만): [('자연어', 1), ('자연어 처리는', 1), ('재미있다', 1), ('처리는', 1), ('처리는 재미있다', 1)]\n",
            "\n",
            "--- Unigram + Bigram + Trigram ---\n",
            "Vocabulary 크기: 19\n",
            "Features: ['기계', '기계 학습', '기계 학습은', '기계 학습은 유용하다', '유용하다', '자연어', '자연어 처리는', '자연어 처리는 재미있다', '자연어 처리와', '자연어 처리와 기계'] ...\n",
            "문장 1 벡터 (non-zero만): [('자연어', 1), ('자연어 처리는', 1), ('자연어 처리는 재미있다', 1), ('재미있다', 1), ('처리는', 1), ('처리는 재미있다', 1)]\n"
          ]
        }
      ],
      "source": [
        "configurations = [\n",
        "    ((1, 1), \"Unigram only\"),\n",
        "    ((2, 2), \"Bigram only\"),\n",
        "    ((3, 3), \"Trigram only\"),\n",
        "    ((1, 2), \"Unigram + Bigram\"),\n",
        "    ((1, 3), \"Unigram + Bigram + Trigram\")\n",
        "]\n",
        "\n",
        "for ngram_range, name in configurations:\n",
        "    print(\"\\n--- %s ---\" % name)\n",
        "    vocab = create_vocabulary(sentences_kr, ngram_range=ngram_range)\n",
        "    print(\"Vocabulary 크기: %d\" % len(vocab))\n",
        "\n",
        "    if len(vocab) > 10:\n",
        "        print(\"Features: %s ...\" % str(vocab[:10]))\n",
        "    else:\n",
        "        print(\"Features: %s\" % str(vocab))\n",
        "\n",
        "    # 첫 번째 문장만 벡터화\n",
        "    vector = text_to_bow_vector(sentences_kr[0], vocab, ngram_range=ngram_range)\n",
        "    print(\"문장 1 벡터 (non-zero만): \", end=\"\")\n",
        "    non_zero = [(vocab[i], int(vector[i])) for i in range(len(vector)) if vector[i] > 0]\n",
        "    print(non_zero)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b14aaf2",
      "metadata": {
        "id": "2b14aaf2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d839cb4",
      "metadata": {
        "id": "0d839cb4"
      },
      "source": [
        "## 6. 연습 문제 2: 문장 유사도 계산\n",
        "\n",
        "두 문장의 BOW 벡터를 만들고, 코사인 유사도를 계산하여\n",
        "문장 간의 유사도를 측정해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c472e02",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "0c472e02"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"코사인 유사도 계산\"\"\"\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm1 = np.linalg.norm(vec1)\n",
        "    norm2 = np.linalg.norm(vec2)\n",
        "    if norm1 == 0 or norm2 == 0:\n",
        "        return 0.0\n",
        "    return dot_product / (norm1 * norm2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "782cbc4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "782cbc4b",
        "outputId": "b8808bd3-56a9-4533-8a8c-a0ce38bfc4f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "연습 문제 2: 문장 유사도 계산\n",
            "======================================================================\n",
            "\n",
            "[입력 문장들]\n",
            "문장 1: 날씨가 좋다\n",
            "문장 2: 날씨가 매우 좋다\n",
            "문장 3: 비가 온다\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"연습 문제 2: 문장 유사도 계산\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 세 개의 문장\n",
        "sentences_sim = [\n",
        "    ['날씨가', '좋다'],\n",
        "    ['날씨가', '매우', '좋다'],\n",
        "    ['비가', '온다']\n",
        "]\n",
        "\n",
        "print(\"\\n[입력 문장들]\")\n",
        "for i, sent in enumerate(sentences_sim, 1):\n",
        "    print(\"문장 %d: %s\" % (i, ' '.join(sent)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef704c36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef704c36",
        "outputId": "9247eccc-44a2-48e5-a1f7-1874393271a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary: ['날씨가', '날씨가 매우', '날씨가 좋다', '매우', '매우 좋다', '비가', '비가 온다', '온다', '좋다']\n"
          ]
        }
      ],
      "source": [
        "# Vocabulary 생성 및 벡터화\n",
        "vocab = create_vocabulary(sentences_sim, ngram_range=(1, 2))\n",
        "vectors = [text_to_bow_vector(sent, vocab, (1, 2)) for sent in sentences_sim]\n",
        "\n",
        "print(\"\\nVocabulary: %s\" % str(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd54795",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebd54795",
        "outputId": "31e2cf17-1e57-4822-cd8c-f36d39fc892e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[문장 간 유사도]\n",
            "문장 1 vs 문장 2: 0.5164\n",
            "  '날씨가 좋다' vs '날씨가 매우 좋다'\n",
            "문장 1 vs 문장 3: 0.0000\n",
            "  '날씨가 좋다' vs '비가 온다'\n",
            "문장 2 vs 문장 3: 0.0000\n",
            "  '날씨가 매우 좋다' vs '비가 온다'\n",
            "\n",
            "✓ '날씨가 좋다'와 '날씨가 매우 좋다'는 높은 유사도를 가집니다.\n",
            "✓ '비가 온다'는 다른 문장들과 낮은 유사도를 가집니다.\n"
          ]
        }
      ],
      "source": [
        "# 모든 문장 쌍의 유사도 계산\n",
        "print(\"\\n[문장 간 유사도]\")\n",
        "for i in range(len(sentences_sim)):\n",
        "    for j in range(i+1, len(sentences_sim)):\n",
        "        sim = cosine_similarity(vectors[i], vectors[j])\n",
        "        print(\"문장 %d vs 문장 %d: %.4f\" % (i+1, j+1, sim))\n",
        "        print(\"  '%s' vs '%s'\" % (' '.join(sentences_sim[i]), ' '.join(sentences_sim[j])))\n",
        "\n",
        "print(\"\\n✓ '날씨가 좋다'와 '날씨가 매우 좋다'는 높은 유사도를 가집니다.\")\n",
        "print(\"✓ '비가 온다'는 다른 문장들과 낮은 유사도를 가집니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c94f49dc",
      "metadata": {
        "id": "c94f49dc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21a6fe22",
      "metadata": {
        "id": "21a6fe22"
      },
      "source": [
        "## 7. 실습 요약\n",
        "\n",
        "### 배운 내용\n",
        "1. **N-gram 생성**: Unigram, Bigram, Trigram\n",
        "2. **Vocabulary 구축**: 여러 문장으로부터 통합 어휘 생성\n",
        "3. **BOW 벡터화**: 문장을 고정 차원 숫자 벡터로 변환\n",
        "4. **문장 유사도**: 코사인 유사도를 이용한 문장 비교\n",
        "\n",
        "### 주요 발견\n",
        "- N-gram을 추가하면 vocabulary 크기가 증가하지만 문맥 정보가 보존됨\n",
        "- Bigram은 인접한 두 단어의 관계를 포착\n",
        "- BOW 벡터를 이용하면 문장 간 유사도를 계산할 수 있음\n",
        "\n",
        "### 다음 단계\n",
        "- **실습 2**: 텍스트 전처리 파이프라인 구축\n",
        "- **실습 3**: 실제 의료 판독문 데이터 분석"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}